\section{Cassandra}
\label{sect:Cassandra}
\subsection{Why Cassandra?}
\label{sect:why}
The Apache Cassandra (C*) database is an Apache Software Foundation project and can be characterized as decentralized, elastic and fault-tolerant according to its website. The use of Cassandra seemed the natural choice as this project is based on Twitter Storm and Twitter uses Cassandra internally too. In addtion there are many use cases for a NoSQL database system like Cassandra especially in a big data environment and we found that it was well suited for our project. In this first section some background information about Cassandra are given and especially those key characteristics are outlined that are important for this project. 

To classify a database system a reasonable approach is to look at its features in respect to the CAP theorem. As stated in the CAP theorem, you can only achieve two of the three main concerns (C)onsistency, (A)vailability and (P)artition tolerance in database systems. 

As a typical NoSQL database C* focusses on availability rather than consistency. One feature to achieve that is a mechanism called "hinted handoff". If a node where a write belongs fails --- C* distributes its data according to a selectable partitioning algorithm, e.g. based on DHTs --- the node that receives the write will create a hint and later "hand off" the hint regarding the write to the intended node. That way Cassanra always stays available for writes.

It achieves partition tolerance by using a gossip protocol for the communication between the nodes in the cluster. This is how nodes become aware of the status of its neighbours and can e.g. trigger actions when nodes become online again to achieve an eventual consistency. Because nodes remain online even if they can't communicate with each other and will resync data once the partition is resolved we aren't guaranteed that all nodes will have the same data either during or after the partition. Cassandra provides the means to apply different levels of consistency depending on the use case. Thus when writes are replicated to additional replica nodes a read operation can wait until all replicas have acknowleged that data to ensure its the most current one.


For us, the two most important features of Cassandra are that it is a clustered database and that it is optimized for write performance, though.

C* is a database system that scales lineary on commodity hardware or cloud infrastructure as well. Depending on our needs it can be easily extended with addional cluster nodes. As our topology can run on as many worker nodes and thus be adapted to different use cases or system loads respectively, we need to make sure that the backend can accomodate different workloads. With Cassandra we have the necessary flexibility to achieve that as is only means to change the central configuration file and start up as many cluster nodes with it as needed to increase the throughput.

Secondly, Cassandra is optimized for write performance and thus is ideally suited for use cases where big data is involved. In such cases, when needing to store masses of real-time data as e.g. from sensors or generated by modern information systems, you need some form of asynchronous write implementation to achieve the necessary throughput. When performing write operations, Cassandra stores values to table specific, in-memory data structures called Memtables. These Memtables are flushed to disk whenever one of the configurable thresholds is exceeded thus being able to immediately acknowlegde a write (after at least an additional entry in the commit log has been made). The proper tuning of these thresholds is important in making the most of available system memory, without bringing the node down for lack of memory. In addtion the log-structured engine avoids overwrites to turn updates into sequential I/O because e.g. of seek penalties.

In the following sections the data model of Cassandra is described and how it is used in this project. Although it doesn't provide typical features found in such traditional relational databases as e.g. joins, transactions or certain aggregate functions this project focussed on developing client-side operator logic on streaming data in the form of plain tuple values and thus doesn't need that additional functionality from the backend. At last the driver binding and its configuration for this project are explained.

\subsection{Data Model}
\label{sect:model}
Cassandra uses row keys to reference a group of columns that should be treated together as a set. For each row we can store name/value pairs which are the columns. As rows we then understand separate entities that hold some set of columns. The basic Cassandra data structures are:
\begin{itemize}
  \item Column
  \item Column family (table)
  \item Keyspace
\end{itemize} 

The column is a name/value pair (and a client-supplied timestamp of when it was last updated), and a column family (table), which is a container for rows that have similar, but not
identical, column sets.

Both row keys and column names can be strings, like relational column names, but they can also be long integers, UUIDs, or any kind of byte array. So there’s some variety to how your key names can be set. This reveals another interesting quality to Cassandra’s columns: they don’t have to be as simple as predefined name/value pairs; you can store useful data in the key itself, not only in the value. 

A keyspace is the outermost container for data in Cassandra, corresponding closely to a relational database. It has the following attributes:
\begin{itemize}
  \item Replication factor
  
  The replication factor refers to the number of nodes that will act as copies (replicas) of each row of data.
  \item Replica placement strategy
  
  There are different strategies that ship with Cassandra for determining which nodes will get copies of which keys.
  \item Column families
  
  A Column family is roughly analagous toa table in the relational model, and is a container for a collection of rows
\end{itemize}

\subsection{Driver Binding and Configuration}
\label{sect:binding}
As driver binding we chose the open-source driver from datastax. This company is offering services around its Cassandra-based enterprise database and is actively developing its driver. New features are discussed and announced regularly. This driver has been chosen because it based on Java and uses CQL as quering language. CQL offers higher abstraction as the legacy Thrift protocol and is considered as its successor. It uses a binary protocol communicating on port 9042 that is supposed to be faster as well. It is provided in the central maven repository and thus can easily be used in project using maven. Apart from defining all the necessary datastructures for C* it provides helper functions for conveniently building the needed queries and to tune additional settings (e.g. port configuration, consistency level for read or write operations etc.)

The binding to our topology is achieved by the use of a CassandraOperator as an UDFBolt. This bolt then is configured for the actual database access by passing a CassandraConfiguration object. The object is instantiated with the following parameters:
\begin{enumerate}
  \item String - name of database keyspace
  \item String - name of table
  \item Primary Key - (compound) primary key
  \item Fields - fields to store from tuple
  \item Boolean - data table or counter
\end{enumerate}
  
The Primary Key is the row key under which the single data sets should be stored. Usually we will specify a compound key here as that will result in wide rows. Wide or dynamic rows are a key feature for NoSQL databases and for such use cases where upcoming data items are stored in addtional columns for a single row key. 

Further, we want to be able to state which columns from a tuple should be stored or --- if no field is given --- or that all fields should be stored. 

Finally, because we want to use Cassandra also for counting purposes (e.g. updating the significance for a user) we have a config parameter telling the CassandraOperator to build a dedicated counting table or a normal table for storing fields. This is necessary since counting columns require a dedicated table which then can only be used for updating the counter column. Usually C* don't have an update semantic and when using UPDATE it will translate to insert which will add or overwrite if key exists. In case of the counter tables and columns respectively an update will actually update the value with a given increment.

With a configuration like new CassandraConfig("citstorm", "user-significance", new Primary Key("user", "tweet"), new Fields(), false) at first the necessary data structures for are created. Since no special Fields have been declared all fields in the tuple coming in will be stored. The field "user" will function as the row key determining on which node this data set will be stored. As a compound primary key is given, the "tweet" column will function as a dynamic column, adding a new column with each new tweet.

In order to create all the datastructures needed to store a tuple, it first has to be analyzed. Therefore always the first tuple is analyzed by the CassandraOperator to identify what objects or primitive data types are actually in it. 

At this point in development for Strings, integers and long datatypes columns with the according C* datatypes are created. All other objects are serialized and stored as byte arrays in Cassandra as blobs. Thus, in a tuple all other datatypes that are not serializable will cause an exception.

The binding and configuration for Cassandra should be useable with as less configuration as possible. Therefore no other settings as the ones described in this section are programmatically changeable. For the purpose in this project a seemless and automatic binding for storing tuples from the Twitter Storm framework was the main focus.
